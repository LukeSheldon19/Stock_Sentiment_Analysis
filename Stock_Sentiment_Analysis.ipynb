{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880db21a-083e-40fc-b1b7-c36a0e21cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711bcff3-1b83-4d08-9ad7-a0d66275cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/LShel/Downloads/archive (3)/Combined_News_DJIA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afedc6f-886e-4694-a80a-9bbaba3baa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for col in df.columns:\n",
    "    if col != 'Date' and col != 'Label':\n",
    "        cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b910670-7c2a-4674-afce-42997fe04744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_strings(string):\n",
    "    if not isinstance(string, str):\n",
    "        return ''\n",
    "    no_p = re.sub(r\"[.]\", '', string)\n",
    "    ft = re.sub(r\"[^a-zA-Z0-9]\", ' ', no_p)\n",
    "    filtered_text = re.sub(r'\\bb\\b', '', ft)\n",
    "    filtered_text = re.sub(r'\\s+', ' ', filtered_text)\n",
    "    filtered_text = filtered_text.strip()\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a03f7c3-075e-4785-8d50-c570e8529aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    s = []\n",
    "    for c in cols:\n",
    "        s.append(filter_strings(row[c]))\n",
    "    sents.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d8847-f0fc-4244-a445-4c3e2f3a556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sents_filt = []\n",
    "\n",
    "for s in tqdm(sents):\n",
    "    filtered = []\n",
    "    for sent in s:\n",
    "        w_ent = []\n",
    "        if isinstance(sent, str):\n",
    "            doc = nlp(sent)\n",
    "            for ent in doc.ents:\n",
    "                w_ent.append(ent.label_)\n",
    "            if 'ORG' in w_ent or 'GPE' in w_ent or 'NORP' in w_ent:\n",
    "                filtered.append(sent)\n",
    "    sents_filt.append(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d02b89d-66ec-49fc-b9fd-438e1961a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_comb = []\n",
    "\n",
    "for sents in sents_filt:\n",
    "    index = 0\n",
    "    s = ''\n",
    "    for sent in sents:\n",
    "        index = index + 1\n",
    "        if index == len(sents):\n",
    "            s += sent\n",
    "        else:\n",
    "            s += sent + ' ' \n",
    "    text_comb.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b46ed67-4e84-45b0-bd7e-a79880218c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "text_filtered = []\n",
    "\n",
    "for t in text_comb:\n",
    "    toks = t.split()\n",
    "    processed_words = [\n",
    "        tok for tok in toks if tok.lower() not in stop_words\n",
    "    ]\n",
    "    processed_sentence = ' '.join(processed_words)\n",
    "\n",
    "    text_filtered.append(processed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c94bf0-3440-43fd-a759-cfb8dec97d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99ff30d-f334-4c7c-95b2-e98e8e4af0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c096bc-9ecf-4862-8702-59fac8e0db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ff9788-ce8f-494b-8ccc-ef51f811e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_cased = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9602576e-8e4f-4eb1-b267-2c77dd02151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "for sent in text_filtered:\n",
    "    encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "    input_ids.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bae1be-94e5-4b4d-97d6-6d78d852700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max Sentence length', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c16682-12ce-4905-b617-7dfc4a99616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a00c8-7598-46f0-97d2-77ec51e6b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "print('padding/truncating all sentences to %d values' % MAX_LEN)\n",
    "print('padding token:\"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', value=0, truncating='post', padding='post')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5edb458b-3f55-4f70-a9e5-1e46d661302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = []\n",
    "\n",
    "for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    attention_mask.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "486b9424-d26d-4e8c-b76f-4ba348b2e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab51df-37c6-474e-99ba-32e31cf72b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_labels, test_labels = train_test_split(input_ids, labels, random_state=42, test_size=0.1)\n",
    "\n",
    "train_mask, test_mask, _, _ = train_test_split(attention_mask, labels, random_state=42, test_size=0.1)\n",
    "\n",
    "train_input, validation_input, train_labels, validation_labels = train_test_split(train_input, train_labels, random_state=42, test_size=0.1)\n",
    "\n",
    "train_mask, validation_mask, _, _ = train_test_split(train_mask, train_mask, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fe4b1-283e-4728-810d-f269060119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---Train---')\n",
    "print('input: ', train_input.shape)\n",
    "print('label: ', train_labels.shape)\n",
    "print('mask: ', np.array(train_mask).shape)\n",
    "\n",
    "print('---Validation---')\n",
    "print('input: ', validation_input.shape)\n",
    "print('label: ', validation_labels.shape)\n",
    "print('mask: ', np.array(validation_mask).shape)\n",
    "\n",
    "print('---Test---')\n",
    "print('input: ', test_input.shape)\n",
    "print('label: ', test_labels.shape)\n",
    "print('mask: ', np.array(test_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254066e6-ee68-4a66-a82a-dcf681b2e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_input = torch.tensor(train_input)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_mask = torch.tensor(train_mask)\n",
    "\n",
    "validation_input = torch.tensor(validation_input)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_mask = torch.tensor(validation_mask)\n",
    "\n",
    "test_input = torch.tensor(test_input)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_mask = torch.tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700c326-b9c0-4bb7-a4ed-fd2b2a3aa638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_data = TensorDataset(train_input, train_mask, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_input, validation_mask, validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_input, test_mask, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7fd41-6cc6-428f-8024-3439d5a0bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2, output_attentions = False, output_hidden_states = False, hidden_dropout_prob=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab4959-8c74-4392-8b40-d3a99c331388",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print(\"The BERT model has {:} different named parameters.\".format(len(params)))\n",
    "\n",
    "print(\"==== Embedding Layer ====\")\n",
    "for p in params[0:5]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"==== First Transformers ====\")\n",
    "for p in params[5:21]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"==== Output Layer ====\")\n",
    "for p in params[-4:]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5b226-6878-43c9-baec-3cd7c92f5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 1e-5, eps = 1e-8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56aeca4-1045-48d3-a4a0-06e1f3fb9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6294a9d-0c24-44dc-93dc-2bd60c2d466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ec54e-59f9-4ba3-b2f8-1b8241cd4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "\n",
    "  print('there are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "  print('we will use the GPU: ', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "  print(\"No GPU available, using the CPU instead\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c1fef-12c4-4359-8721-81642479347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ===================================\n",
    "    #              Training\n",
    "    # ===================================\n",
    "\n",
    "    print(\"======= Epoch {:} / {:} =======\".format(epoch_i+1, epochs))\n",
    "    print(\"Training...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # Progress update every 40 batches\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            print(\"Batch {:>5,} of {:>5,}.     Elapsed: {:}\".format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "    \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device).long()\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels)\n",
    "    \n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"   Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"   Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ===================================\n",
    "    #             Validation\n",
    "    # ===================================\n",
    "\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids,\n",
    "                      token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "    \n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "  \n",
    "    print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80379f2-43cb-40eb-b808-bda986dd3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting labels for {:,} test sentences\".format(len(test_input)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prediction, true_labels = [], []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    prediction.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print(\" DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870793b-b2e6-4cce-ad0a-05d79ab33b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "flat_prediction = [item for sublist in prediction for item in sublist]\n",
    "flat_prediction = np.argmax(flat_prediction, axis=1).flatten()\n",
    "\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_prediction)\n",
    "\n",
    "print(\"MCC: %.3f\" %mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f478fe5-004f-46e3-b3dd-3dd03c9ef950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(flat_true_labels, flat_prediction)\n",
    "\n",
    "print(\"ACC: %.3f\" %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01990f-df14-4b05-a591-f5cdf5eb552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
